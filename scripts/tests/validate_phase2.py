#!/usr/bin/env python
"""
Phase 2 Validation Script
Comprehensive validation of all Phase 2 components working together.
"""

import os
import sys
from datetime import datetime

os.environ['DATABASE_URL'] = 'postgresql+psycopg2://market:market@localhost:5433/marketdb'
sys.path.insert(0, os.path.join(os.path.dirname(__file__), '..'))

from src.news.fetcher import NewsFetcher
from src.news.parser import NewsParser
from src.news.embedder import NewsEmbedder
from src.news.storage import NewsStorage
from src.news.rag import NewsRAG
from src.utils.logging import StructuredLogger, setup_logging
from src.utils.config import load_yaml_config


def print_header(title):
    print("\n" + "="*80)
    print(f"  {title}")
    print("="*80)


def print_section(title):
    print(f"\n{title}")
    print("-"*80)


def validate_components():
    """Validate all Phase 2 components."""
    config = load_yaml_config('settings')
    logger = StructuredLogger(setup_logging(config.get('logging', {})))
    
    print_header("PHASE 2 VALIDATION: COMPREHENSIVE PIPELINE TEST")
    
    # 1. Component Initialization
    print_section("âœ“ INITIALIZING COMPONENTS")
    
    fetcher = NewsFetcher(logger)
    print(f"  âœ“ NewsFetcher initialized")
    print(f"    - Ticker extraction: {'LLM (Ollama)' if fetcher.ticker_extractor.ollama_available else 'Fallback Mapping'}")
    print(f"    - RSS feeds configured: {len(fetcher.rss_feeds)}")
    
    parser = NewsParser(logger, use_ollama=False, use_finbert=True)
    print(f"  âœ“ NewsParser initialized")
    print(f"    - FinBERT: {'Enabled' if parser.use_finbert else 'Disabled'}")
    print(f"    - Model loaded: {parser.finbert_model is not None}")
    
    embedder = NewsEmbedder()
    print(f"  âœ“ NewsEmbedder initialized")
    print(f"    - Embedding dimension: {embedder.embedding_dim}")
    print(f"    - Model: {embedder.model.get_sentence_embedding_dimension()} dimensions")
    
    storage = NewsStorage()
    print(f"  âœ“ NewsStorage initialized")
    print(f"    - Database connected: {storage.engine is not None}")
    
    rag = NewsRAG()
    print(f"  âœ“ NewsRAG initialized")
    print(f"    - Vector retrieval ready: True")
    
    # 2. Fetch Test Data
    print_section("ğŸ“° FETCHING TEST DATA")
    raw_news = fetcher.fetch_all_feeds(hours_lookback=48)
    
    if raw_news:
        print(f"  âœ“ Fetched {len(raw_news)} articles from RSS")
        print(f"\n  Sample articles with extracted tickers:")
        for i, item in enumerate(raw_news[:3], 1):
            tickers = ', '.join(item.get('tickers', ['SPY']))
            print(f"    {i}. [{tickers}] {item['headline'][:60]}")
    else:
        print(f"  âš ï¸  No live articles fetched, using test data")
        raw_news = [
            {
                'headline': 'Apple Q1 earnings beat expectations',
                'content': 'Apple reported strong revenue growth in Q1 2026.',
                'tickers': ['AAPL'],
                'source': 'Test',
                'url': 'https://example.com/1',
                'published_at': None
            },
            {
                'headline': 'Tesla production slows amid supply issues',
                'content': 'Tesla faces manufacturing challenges.',
                'tickers': ['TSLA'],
                'source': 'Test',
                'url': 'https://example.com/2',
                'published_at': None
            },
        ]
    
    # 3. Sentiment Analysis
    print_section("ğŸ¯ SENTIMENT ANALYSIS (FinBERT)")
    parsed_news = []
    for item in raw_news[:10]:  # Limit to 10 for testing
        headline = item.get('headline', '')
        content = item.get('content', '')
        sentiment = parser.extract_sentiment(f"{headline} {content}", use_llm=False)
        
        parsed_news.append({
            **item,
            'sentiment_score': sentiment,
            'novelty_score': 0.75
        })
    
    print(f"  âœ“ Analyzed {len(parsed_news)} articles")
    bullish = sum(1 for item in parsed_news if item['sentiment_score'] > 0.3)
    bearish = sum(1 for item in parsed_news if item['sentiment_score'] < -0.3)
    neutral = len(parsed_news) - bullish - bearish
    
    print(f"\n  Sentiment Distribution:")
    print(f"    ğŸ“ˆ Bullish:  {bullish:2d} ({100*bullish/len(parsed_news):5.1f}%)")
    print(f"    ğŸ“‰ Bearish:  {bearish:2d} ({100*bearish/len(parsed_news):5.1f}%)")
    print(f"    â¡ï¸  Neutral:  {neutral:2d} ({100*neutral/len(parsed_news):5.1f}%)")
    
    # Show sample sentiments
    print(f"\n  Sample sentiment scores:")
    for item in parsed_news[:3]:
        sentiment = item['sentiment_score']
        emoji = "ğŸ“ˆ" if sentiment > 0.3 else "ğŸ“‰" if sentiment < -0.3 else "â¡ï¸"
        print(f"    {emoji} {sentiment:+.3f}: {item['headline'][:50]}")
    
    # 4. Embedding Generation
    print_section("ğŸ§  EMBEDDING GENERATION")
    texts = [f"{item['headline']} {item.get('content', '')}" for item in parsed_news]
    embeddings = embedder.batch_embed(texts)
    
    for i, item in enumerate(parsed_news):
        item['embedding'] = embeddings[i]
    
    print(f"  âœ“ Generated {len(embeddings)} embeddings")
    print(f"    Dimension: {embedder.embedding_dim}")
    print(f"    Sample embedding stats:")
    sample_emb = embeddings[0]
    print(f"      - Min: {min(sample_emb):.4f}")
    print(f"      - Max: {max(sample_emb):.4f}")
    print(f"      - Mean: {sum(sample_emb)/len(sample_emb):.4f}")
    
    # 5. Storage
    print_section("ğŸ’¾ DATABASE STORAGE")
    initial_count = storage.get_news_count()
    print(f"  Database state before storage: {initial_count} articles")
    
    stored_ids = []
    for item in parsed_news:
        try:
            news_id = storage.store_news(
                headline=item['headline'],
                content=item.get('content', ''),
                source=item.get('source', 'Unknown'),
                url=item.get('url', ''),
                tickers=item.get('tickers', []),
                embedding=item['embedding'],
                sentiment_score=item['sentiment_score'],
                published_at=item.get('published_at')
            )
            stored_ids.append(news_id)
        except Exception as e:
            print(f"    âš ï¸  Failed to store article: {e}")
    
    final_count = storage.get_news_count()
    print(f"  âœ“ Stored {len(stored_ids)} articles")
    print(f"    Database state: {initial_count} â†’ {final_count} articles")
    
    # 6. RAG Retrieval
    print_section("ğŸ” RAG RETRIEVAL TEST")
    test_queries = [
        "earnings revenue growth",
        "production problems supply",
    ]
    
    for query in test_queries[:2]:
        print(f"\n  Query: \"{query}\"")
        results = rag.retrieve_similar_news(query, limit=2, recency_weight=0.3)
        if results:
            print(f"    Found {len(results)} results:")
            for i, (score, article) in enumerate(results[:2], 1):
                print(f"      {i}. Score: {score:.3f}")
                print(f"         {article['headline'][:50]}...")
        else:
            print(f"    No results found")
    
    # 7. Ticker Analysis
    print_section("ğŸ“Š TICKER CONTEXT ANALYSIS")
    for ticker in ['AAPL', 'TSLA']:
        context = rag.get_ticker_context(ticker, limit=3)
        if context and context.get('count', 0) > 0:
            articles = context.get('news_items', [])
            avg_sentiment = context.get('avg_sentiment', 0)
            emoji = "ğŸ“ˆ" if avg_sentiment > 0 else "ğŸ“‰" if avg_sentiment < 0 else "â¡ï¸"
            print(f"\n  {emoji} {ticker}:")
            print(f"     Sentiment: {avg_sentiment:+.3f}")
            print(f"     Articles: {len(articles)}")
            for article in articles[:2]:
                print(f"       â€¢ {article.get('headline', 'Unknown')[:50]}...")
        else:
            print(f"\n  {ticker}: No articles found")
    
    # Final Summary
    print_header("âœ… PHASE 2 VALIDATION COMPLETE")
    print(f"""
  Status: ALL SYSTEMS OPERATIONAL
  
  Components Validated:
    âœ“ NewsFetcher - Fetches & extracts tickers
    âœ“ NewsParser - Analyzes sentiment with FinBERT
    âœ“ NewsEmbedder - Generates 768-dim embeddings
    âœ“ NewsStorage - Persists to PostgreSQL
    âœ“ NewsRAG - Retrieves semantic context
  
  Key Metrics:
    â€¢ Articles processed: {len(parsed_news)}
    â€¢ Articles stored: {len(stored_ids)}
    â€¢ Total in database: {final_count}
    â€¢ Sentiment distribution: {bullish}â†‘ {bearish}â†“ {neutral}â†’
    â€¢ Embedding dimension: {embedder.embedding_dim}
  
  Ready for Next Phase:
    â†’ Candidates Selector (uses news sentiment)
    â†’ Feature Engineering (combines sentiment + technical)
    â†’ ML Training (XGBoost with features)
    â†’ Agent Ensemble (analyst, bull, bear, risk)
    """)


if __name__ == '__main__':
    try:
        validate_components()
    except Exception as e:
        print(f"\nâŒ Validation failed: {e}", file=sys.stderr)
        import traceback
        traceback.print_exc()
        sys.exit(1)
