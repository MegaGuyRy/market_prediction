# ML Model Configuration

xgboost:
  # Training Parameters
  training:
    test_size: 0.2
    random_state: 42
    cv_folds: 5
    lookback_days: 730  # 2 years training data
    forward_days: 1  # Predict 1-day forward return
    retrain_frequency_days: 7  # Weekly retraining
    
  # Hyperparameters
  hyperparameters:
    n_estimators: 200
    max_depth: 6
    learning_rate: 0.05
    subsample: 0.8
    colsample_bytree: 0.8
    min_child_weight: 3
    gamma: 0.1
    reg_alpha: 0.1
    reg_lambda: 1.0
    objective: "reg:squarederror"
    eval_metric: "rmse"
    random_state: 42
    n_jobs: -1

  # Signal Generation
  signal_thresholds:
    buy_threshold: 0.01  # Predicted return > 1% → BUY
    sell_threshold: -0.01  # Predicted return < -1% → SELL
    min_confidence: 0.6  # Only signals with >60% confidence
    
  # Feature Importance
  top_features: 20  # Track top N features for explainability

# LSTM (Future v1.1+)
lstm:
  enabled: false
  sequence_length: 20
  hidden_units: 128
  dropout: 0.2
  epochs: 50
  batch_size: 32

# Backtest Configuration
backtest:
  start_date: "2022-01-01"
  end_date: "2024-12-31"
  initial_capital: 100000
  commission: 0.0  # Paper trading, no commission
  slippage: 0.0  # No slippage modeling
  metrics:
    - "sharpe_ratio"
    - "max_drawdown"
    - "win_rate"
    - "total_return"
    - "avg_trade_duration"
